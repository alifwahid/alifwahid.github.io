---
layout     : post
title      : "The Problematic Y"
tags       : [curiosity, problem definition, question formulation]
categories : [philosophy, psychology]
excerpt    : How I try to think about a problem before rushing to solutions.
---

**Contents**
1. ToC will be auto-placed here
{:toc}

## Thinking is not fun

I recently stumbled on a 2014 [paper][doilink] in the journal Science, titled
'_Just think: The challenges of the disengaged mind_'. Apparently people do not
enjoy the act of simply thinking consciously for the sake of thinking. Instead,
they prefer to be doing something mundane, or even shocking (quite
literally). Certainly surprised me, because I love to just think and do
nothing! However, I know from past experience that consciously thinking about a
problem is definitely not fun. I seem to have a penchant for thinking about
solutions without exploring, in detail, what the problem is. So to help me
overcome that urge, over the years, I've relied on a thinking tool that I call
_The Problematic Y_.

[doilink]: http://science.sciencemag.org/content/345/6192/75


## The right questions

It's generally accepted that asking the right questions is far more important
than finding the relevant answers. Over time, only the questions tend to endure
while any set of answers typically get revised heavily (if not discarded
entirely). I've found that it helps to periodically remind myself about two
key questions:

1. What is the problem?
2. Why is it important?

The first is obvious enough. The second, however, runs into the infinite
regress issue of any "why" question. In other words, it's always a subjective
debate when justifying the importance of a problem. That never excites me. I
absolutely hate the prospect of justifying, to others, a problem that somehow
ignited my curiosity. Fortunately, I've learnt from reading Daniel Dennett's
wonderful books that the "why" question above is actually two separate
questions in disguise, as follows.

1. How did it come to be a problem?
2. What will happen after solving it?

The first is about the past, and is asking for narratives. The second is about
the future, and is asking for consequences. Both are valid regardless of any
given solution to a problem. So the importance of a problem can be justified in
terms of past narratives and future consequences. All other details in that
justification effort really fall into those two categories. Thus my initial two
questions are actually better remembered as three questions, which I've
illustrated below in the image of an upper case Y.

![problematic-y]({{ "/imgs/problematic_y.svg" | absolute_url }})

Short placeholders for these questions are _narratives_ (left branch of the Y),
_definition_ (trunk of the Y) and _consequences_ (right branch of the Y). You
can read this diagram from left to right. The three questions are framed
correspondingly in the past, present and future tenses to aid comprehension.
There's not a lot to be said about definition other than that it needs to be
short and sharp. The challenges lie in pondering narratives and consequences.


## Narratives

The plural here is noteworthy. There are always many narratives, never only
one, when justifying a problem. I like to think of this as a multidimensional
hypercube where each dimension is a narrative, and thus the position of a
problem in this hyperspace necessarily comprises coordinate narratives.

What follows is my shortlist of dimensions to think about, which is obviously
incomplete. I find that such pondering tends to highlight the essential
constraints of a problem that, ultimately, a good solution must satisfy.

### History

This is about the novelty and prevalence of a problem. Is it new or old? How
often does it rear its ugly head? How long has it existed? If it's a
long-standing problem, how come it's still unsolved? How much has this problem
cost people (i.e., use a suitable measure of cost, not just money)?

### Psychology

Whose problem is it? Is it a need (which is compulsory) or a want (which is
optional)? Do people recognise it as a problem or are they unaware of its
existence? Have people become habituated to it to such an extent that it's not
worth solving?

### Philosophy

This is largely a concern with epistemology. What assumptions are implicit in
the problem definition? What happens if you remove an assumption? Is it still a
problem in that case? Does it worsen? Is it an ethical dilemma?


## Consequences

It's a straightforward expectation that solving a problem will have many
consequences. We're all familiar with the phenomenon of _unintended
consequences_. It's not easy to predict all the effects of our actions, but it
helps to extrapolate from the narratives figured out earlier, assuming that the
problem has been solved. Furthermore, Neil Postman has pointed out couple of
key questions as far as consequences are concerned.

1. What new problems might be created afterwards?
2. Who might be harmed and who might be empowered?

Regardless of the narratives of a problem, addressing Postman's two questions
above are instantly beneficial, because they hint at the two most frequent
sources of unintended consequences. The wonderful book by Daniel Kahneman,
'_Thinking, Fast and Slow_', pointed out a particularly pernicious consequence
of change that leads to losers and winners: losers always resist such changes
vehemently because the pain of losing is a stronger emotion than the converse
joy of winning. This is the insight behind Postman's second question above.

More broadly, thinking about consequences of any given problem has typically
led me to consider risk and reward in a new light. That's how I came across
Kahneman's wonderful book. In addition, Nassim Nicholas Taleb has written some
thought provoking books on these topics. The key lesson I've taken away from
Taleb's writing is the wisdom of restricting losses and unrestricting
gains. That is, regardless of the risk that maybe inherent in a problem, the
correct action is to focus on manipulating the gains and losses, rather than
the probability. Taleb calls it fixing the exposure and not the probability,
because we cannot estimate probabilities accurately for rare events. So control
your exposure in all the ways you can (e.g., insurance, contracts), and ignore
probabilities.


## An intuition pump

Daniel Dennett coined the clever term _intuition pump_, which refers to a
thought experiment or a thinking tool that helps to see the main points of a
problem. I strongly recommend his book _Intuition Pumps and Other Tools For
Thinking_. What I've learned from that book (and other books by Dennett) is
that it is indeed possible to think clearly, with a little effort, even if it's
not fun (as the _Science_ paper at the start of this post made clear). Hence
_The Problematic Y_ has been a thoroughly helpful intuition pump for me.
